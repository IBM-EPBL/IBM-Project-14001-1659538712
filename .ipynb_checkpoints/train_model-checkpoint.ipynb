{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "85b65cb9-42d3-4311-b599-5b1979fab14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "750da540-1efe-446a-ba31-2678d9c5bf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20630, 26)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('./Dataset/train.txt',sep=' ')\n",
    "train_dataset.drop(train_dataset.columns[[26,27]], axis=1,inplace=True)\n",
    "col_name = ['id','cycle','set1','set2','set3','s1','s2','s3','s4','s5','s6','s7','s8']+['s9','s10','s11','s12','s13','s14','s14','s15','s16','s17','s18','s19','s20']\n",
    "train_dataset.columns = col_name\n",
    "#print(train_dataset.head(2))\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "120d0dac-84cd-4576-9131-e5a2a181c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13095, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.11</td>\n",
       "      <td>1579.12</td>\n",
       "      <td>1395.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.92</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8127.46</td>\n",
       "      <td>8.4238</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.91</td>\n",
       "      <td>23.3467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13090</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.24</td>\n",
       "      <td>1599.45</td>\n",
       "      <td>1415.79</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>520.69</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8213.28</td>\n",
       "      <td>8.4715</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.65</td>\n",
       "      <td>23.1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.22</td>\n",
       "      <td>1595.69</td>\n",
       "      <td>1422.05</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.05</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8210.85</td>\n",
       "      <td>8.4512</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.57</td>\n",
       "      <td>23.2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.44</td>\n",
       "      <td>1593.15</td>\n",
       "      <td>1406.82</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.18</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8217.24</td>\n",
       "      <td>8.4569</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.62</td>\n",
       "      <td>23.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.26</td>\n",
       "      <td>1594.99</td>\n",
       "      <td>1419.36</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.33</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8220.48</td>\n",
       "      <td>8.4711</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.66</td>\n",
       "      <td>23.2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13095 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cycle    set1    set2   set3      s1      s2       s3       s4  \\\n",
       "0        1      2 -0.0027 -0.0003  100.0  518.67  641.71  1588.45  1395.42   \n",
       "1        1      3  0.0003  0.0001  100.0  518.67  642.46  1586.94  1401.34   \n",
       "2        1      4  0.0042  0.0000  100.0  518.67  642.44  1584.12  1406.42   \n",
       "3        1      5  0.0014  0.0000  100.0  518.67  642.51  1587.19  1401.92   \n",
       "4        1      6  0.0012  0.0003  100.0  518.67  642.11  1579.12  1395.13   \n",
       "...    ...    ...     ...     ...    ...     ...     ...      ...      ...   \n",
       "13090  100    194  0.0049  0.0000  100.0  518.67  643.24  1599.45  1415.79   \n",
       "13091  100    195 -0.0011 -0.0001  100.0  518.67  643.22  1595.69  1422.05   \n",
       "13092  100    196 -0.0006 -0.0003  100.0  518.67  643.44  1593.15  1406.82   \n",
       "13093  100    197 -0.0038  0.0001  100.0  518.67  643.26  1594.99  1419.36   \n",
       "13094  100    198  0.0013  0.0003  100.0  518.67  642.95  1601.62  1424.99   \n",
       "\n",
       "          s5  ...     s12      s13      s14     s14   s15  s16   s17    s18  \\\n",
       "0      14.62  ...  522.16  2388.06  8139.62  8.3803  0.03  393  2388  100.0   \n",
       "1      14.62  ...  521.97  2388.03  8130.10  8.4441  0.03  393  2388  100.0   \n",
       "2      14.62  ...  521.38  2388.05  8132.90  8.3917  0.03  391  2388  100.0   \n",
       "3      14.62  ...  522.15  2388.03  8129.54  8.4031  0.03  390  2388  100.0   \n",
       "4      14.62  ...  521.92  2388.08  8127.46  8.4238  0.03  392  2388  100.0   \n",
       "...      ...  ...     ...      ...      ...     ...   ...  ...   ...    ...   \n",
       "13090  14.62  ...  520.69  2388.00  8213.28  8.4715  0.03  394  2388  100.0   \n",
       "13091  14.62  ...  521.05  2388.09  8210.85  8.4512  0.03  395  2388  100.0   \n",
       "13092  14.62  ...  521.18  2388.04  8217.24  8.4569  0.03  395  2388  100.0   \n",
       "13093  14.62  ...  521.33  2388.08  8220.48  8.4711  0.03  395  2388  100.0   \n",
       "13094  14.62  ...  521.07  2388.05  8214.64  8.4903  0.03  396  2388  100.0   \n",
       "\n",
       "         s19      s20  \n",
       "0      39.02  23.3916  \n",
       "1      39.08  23.4166  \n",
       "2      39.00  23.3737  \n",
       "3      38.99  23.4130  \n",
       "4      38.91  23.3467  \n",
       "...      ...      ...  \n",
       "13090  38.65  23.1974  \n",
       "13091  38.57  23.2771  \n",
       "13092  38.62  23.2051  \n",
       "13093  38.66  23.2699  \n",
       "13094  38.70  23.1855  \n",
       "\n",
       "[13095 rows x 26 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('./Dataset/test.txt',sep=' ')\n",
    "test_dataset.drop(test_dataset.columns[[26,27]], axis=1,inplace=True)\n",
    "test_dataset.columns = col_name\n",
    "#print(train_dataset.head(2))\n",
    "print(test_dataset.shape)\n",
    "test_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "68ea71b9-eb49-45fe-a68a-373d1d9ce7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   more  id\n",
      "0    98   1\n",
      "1    69   2\n",
      "2    82   3\n",
      "3    91   4\n",
      "4    93   5\n"
     ]
    }
   ],
   "source": [
    "truth_ds = pd.read_csv('./Dataset/truth.txt',sep=' ')\n",
    "truth_ds.drop(truth_ds.columns[[1]], axis=1,inplace=True)\n",
    "truth_ds.columns = ['more']\n",
    "truth_ds['id'] = truth_ds.index+1\n",
    "print(truth_ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8e15201a-8fa8-45da-8421-91d8e365004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  max\n",
       "0   1   31\n",
       "1   2   49\n",
       "2   3  126\n",
       "3   4  106\n",
       "4   5   98"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul=pd.DataFrame(test_dataset.groupby(\"id\")['cycle'].max()).reset_index()\n",
    "rul.columns = ['id','max']\n",
    "rul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "600b304b-c9ff-4df8-9fe1-2aa32d0833bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>more</th>\n",
       "      <th>id</th>\n",
       "      <th>rtf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   more  id    rtf\n",
       "0    98   1  129.0\n",
       "1    69   2  118.0\n",
       "2    82   3  208.0\n",
       "3    91   4  197.0\n",
       "4    93   5  191.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_ds['rtf']=truth_ds['more']+rul[\"max\"]\n",
    "truth_ds.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "546ebd9b-3df6-4dcb-9520-582944e500bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>more</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "      <td>98.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "      <td>98.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "      <td>98.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "      <td>98.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.11</td>\n",
       "      <td>1579.12</td>\n",
       "      <td>1395.13</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8127.46</td>\n",
       "      <td>8.4238</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.91</td>\n",
       "      <td>23.3467</td>\n",
       "      <td>98.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle    set1    set2   set3      s1      s2       s3       s4     s5  \\\n",
       "0   1      2 -0.0027 -0.0003  100.0  518.67  641.71  1588.45  1395.42  14.62   \n",
       "1   1      3  0.0003  0.0001  100.0  518.67  642.46  1586.94  1401.34  14.62   \n",
       "2   1      4  0.0042  0.0000  100.0  518.67  642.44  1584.12  1406.42  14.62   \n",
       "3   1      5  0.0014  0.0000  100.0  518.67  642.51  1587.19  1401.92  14.62   \n",
       "4   1      6  0.0012  0.0003  100.0  518.67  642.11  1579.12  1395.13  14.62   \n",
       "\n",
       "   ...      s14     s14   s15  s16   s17    s18    s19      s20  more    ttf  \n",
       "0  ...  8139.62  8.3803  0.03  393  2388  100.0  39.02  23.3916  98.0  127.0  \n",
       "1  ...  8130.10  8.4441  0.03  393  2388  100.0  39.08  23.4166  98.0  126.0  \n",
       "2  ...  8132.90  8.3917  0.03  391  2388  100.0  39.00  23.3737  98.0  125.0  \n",
       "3  ...  8129.54  8.4031  0.03  390  2388  100.0  38.99  23.4130  98.0  124.0  \n",
       "4  ...  8127.46  8.4238  0.03  392  2388  100.0  38.91  23.3467  98.0  123.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#truth_ds.drop(\"more\", axis=1, inplace=True)\n",
    "test_dataset=test_dataset.merge(truth_ds, on= ['id'], how= \"left\")\n",
    "test_dataset[ 'ttf']=test_dataset['rtf'] - test_dataset['cycle']\n",
    "test_dataset.drop ('rtf', axis=1, inplace=True)\n",
    "test_dataset. head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ba2cd2de-469d-4ad4-9b63-59cc6a1cb43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.10</td>\n",
       "      <td>1584.47</td>\n",
       "      <td>1398.37</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8132.85</td>\n",
       "      <td>8.4108</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.98</td>\n",
       "      <td>23.3669</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle    set1    set2   set3      s1      s2       s3       s4     s5  \\\n",
       "0   1      2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14  14.62   \n",
       "1   1      3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20  14.62   \n",
       "2   1      4  0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87  14.62   \n",
       "3   1      5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22  14.62   \n",
       "4   1      6 -0.0043 -0.0001  100.0  518.67  642.10  1584.47  1398.37  14.62   \n",
       "\n",
       "   ...      s13      s14     s14   s15  s16   s17    s18    s19      s20  ttf  \n",
       "0  ...  2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00  23.4236  190  \n",
       "1  ...  2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95  23.3442  189  \n",
       "2  ...  2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88  23.3739  188  \n",
       "3  ...  2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90  23.4044  187  \n",
       "4  ...  2388.03  8132.85  8.4108  0.03  391  2388  100.0  38.98  23.3669  186  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[ 'ttf'] = train_dataset.groupby([\"id\"])['cycle'].transform(max)-train_dataset['cycle']\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8477e845-843a-495e-989d-b8813956f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  cycle    set1    set2   set3      s1      s2       s3       s4  \\\n",
      "0        1      2 -0.0027 -0.0003  100.0  518.67  641.71  1588.45  1395.42   \n",
      "1        1      3  0.0003  0.0001  100.0  518.67  642.46  1586.94  1401.34   \n",
      "2        1      4  0.0042  0.0000  100.0  518.67  642.44  1584.12  1406.42   \n",
      "3        1      5  0.0014  0.0000  100.0  518.67  642.51  1587.19  1401.92   \n",
      "4        1      6  0.0012  0.0003  100.0  518.67  642.11  1579.12  1395.13   \n",
      "...    ...    ...     ...     ...    ...     ...     ...      ...      ...   \n",
      "13090  100    194  0.0049  0.0000  100.0  518.67  643.24  1599.45  1415.79   \n",
      "13091  100    195 -0.0011 -0.0001  100.0  518.67  643.22  1595.69  1422.05   \n",
      "13092  100    196 -0.0006 -0.0003  100.0  518.67  643.44  1593.15  1406.82   \n",
      "13093  100    197 -0.0038  0.0001  100.0  518.67  643.26  1594.99  1419.36   \n",
      "13094  100    198  0.0013  0.0003  100.0  518.67  642.95  1601.62  1424.99   \n",
      "\n",
      "          s5  ...     s14   s15  s16   s17    s18    s19      s20  more  \\\n",
      "0      14.62  ...  8.3803  0.03  393  2388  100.0  39.02  23.3916  98.0   \n",
      "1      14.62  ...  8.4441  0.03  393  2388  100.0  39.08  23.4166  98.0   \n",
      "2      14.62  ...  8.3917  0.03  391  2388  100.0  39.00  23.3737  98.0   \n",
      "3      14.62  ...  8.4031  0.03  390  2388  100.0  38.99  23.4130  98.0   \n",
      "4      14.62  ...  8.4238  0.03  392  2388  100.0  38.91  23.3467  98.0   \n",
      "...      ...  ...     ...   ...  ...   ...    ...    ...      ...   ...   \n",
      "13090  14.62  ...  8.4715  0.03  394  2388  100.0  38.65  23.1974   NaN   \n",
      "13091  14.62  ...  8.4512  0.03  395  2388  100.0  38.57  23.2771   NaN   \n",
      "13092  14.62  ...  8.4569  0.03  395  2388  100.0  38.62  23.2051   NaN   \n",
      "13093  14.62  ...  8.4711  0.03  395  2388  100.0  38.66  23.2699   NaN   \n",
      "13094  14.62  ...  8.4903  0.03  396  2388  100.0  38.70  23.1855   NaN   \n",
      "\n",
      "         ttf  label_bc  \n",
      "0      127.0         0  \n",
      "1      126.0         0  \n",
      "2      125.0         0  \n",
      "3      124.0         0  \n",
      "4      123.0         0  \n",
      "...      ...       ...  \n",
      "13090    NaN         0  \n",
      "13091    NaN         0  \n",
      "13092    NaN         0  \n",
      "13093    NaN         0  \n",
      "13094    NaN         0  \n",
      "\n",
      "[13095 rows x 29 columns]\n",
      "        id  cycle    set1    set2   set3      s1      s2       s3       s4  \\\n",
      "0        1      2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14   \n",
      "1        1      3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20   \n",
      "2        1      4  0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87   \n",
      "3        1      5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22   \n",
      "4        1      6 -0.0043 -0.0001  100.0  518.67  642.10  1584.47  1398.37   \n",
      "...    ...    ...     ...     ...    ...     ...     ...      ...      ...   \n",
      "20625  100    196 -0.0004 -0.0003  100.0  518.67  643.49  1597.98  1428.63   \n",
      "20626  100    197 -0.0016 -0.0005  100.0  518.67  643.54  1604.50  1433.58   \n",
      "20627  100    198  0.0004  0.0000  100.0  518.67  643.42  1602.46  1428.18   \n",
      "20628  100    199 -0.0011  0.0003  100.0  518.67  643.23  1605.26  1426.53   \n",
      "20629  100    200 -0.0032 -0.0005  100.0  518.67  643.85  1600.38  1432.14   \n",
      "\n",
      "          s5  ...      s14     s14   s15  s16   s17    s18    s19      s20  \\\n",
      "0      14.62  ...  8131.49  8.4318  0.03  392  2388  100.0  39.00  23.4236   \n",
      "1      14.62  ...  8133.23  8.4178  0.03  390  2388  100.0  38.95  23.3442   \n",
      "2      14.62  ...  8133.83  8.3682  0.03  392  2388  100.0  38.88  23.3739   \n",
      "3      14.62  ...  8133.80  8.4294  0.03  393  2388  100.0  38.90  23.4044   \n",
      "4      14.62  ...  8132.85  8.4108  0.03  391  2388  100.0  38.98  23.3669   \n",
      "...      ...  ...      ...     ...   ...  ...   ...    ...    ...      ...   \n",
      "20625  14.62  ...  8137.60  8.4956  0.03  397  2388  100.0  38.49  22.9735   \n",
      "20626  14.62  ...  8136.50  8.5139  0.03  395  2388  100.0  38.30  23.1594   \n",
      "20627  14.62  ...  8141.05  8.5646  0.03  398  2388  100.0  38.44  22.9333   \n",
      "20628  14.62  ...  8139.29  8.5389  0.03  395  2388  100.0  38.29  23.0640   \n",
      "20629  14.62  ...  8137.33  8.5036  0.03  396  2388  100.0  38.37  23.0522   \n",
      "\n",
      "       ttf  label_bc  \n",
      "0      190         0  \n",
      "1      189         0  \n",
      "2      188         0  \n",
      "3      187         0  \n",
      "4      186         0  \n",
      "...    ...       ...  \n",
      "20625    4         1  \n",
      "20626    3         1  \n",
      "20627    2         1  \n",
      "20628    1         1  \n",
      "20629    0         1  \n",
      "\n",
      "[20630 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = train_dataset.copy()\n",
    "df_test = test_dataset.copy()\n",
    "period = 30\n",
    "df_train['label_bc'] = df_train [\"ttf\"].apply(lambda x: 1 if x <= period else 0)\n",
    "df_test['label_bc'] = df_test ['ttf'].apply(lambda x: 1 if x <= period else 0)\n",
    "print(df_test)\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b4c57e7b-648b-4bc8-83d5-1a87d719466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000e+00  2.00000e+00  1.90000e-03 ...  3.90000e+01  2.34236e+01\n",
      "   1.90000e+02]\n",
      " [ 1.00000e+00  3.00000e+00 -4.30000e-03 ...  3.89500e+01  2.33442e+01\n",
      "   1.89000e+02]\n",
      " [ 1.00000e+00  4.00000e+00  7.00000e-04 ...  3.88800e+01  2.33739e+01\n",
      "   1.88000e+02]\n",
      " ...\n",
      " [ 1.00000e+02  1.98000e+02  4.00000e-04 ...  3.84400e+01  2.29333e+01\n",
      "   2.00000e+00]\n",
      " [ 1.00000e+02  1.99000e+02 -1.10000e-03 ...  3.82900e+01  2.30640e+01\n",
      "   1.00000e+00]\n",
      " [ 1.00000e+02  2.00000e+02 -3.20000e-03 ...  3.83700e+01  2.30522e+01\n",
      "   0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.iloc[ : , : -1].values\n",
    "y_train = df_train. iloc[: , -1:].values\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a15732be-f0b5-487d-b678-9fea9d8cf6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model = model.fit(x_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9463fa2b-36a4-4840-a1f0-5cde5e89d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[ 1.00000e+00  2.00000e+00 -2.70000e-03 ...  2.33916e+01  9.80000e+01\n",
      "   1.27000e+02]\n",
      " [ 1.00000e+00  3.00000e+00  3.00000e-04 ...  2.34166e+01  9.80000e+01\n",
      "   1.26000e+02]\n",
      " [ 1.00000e+00  4.00000e+00  4.20000e-03 ...  2.33737e+01  9.80000e+01\n",
      "   1.25000e+02]\n",
      " ...\n",
      " [ 1.00000e+02  1.96000e+02 -6.00000e-04 ...  2.32051e+01          nan\n",
      "           nan]\n",
      " [ 1.00000e+02  1.97000e+02 -3.80000e-03 ...  2.32699e+01          nan\n",
      "           nan]\n",
      " [ 1.00000e+02  1.98000e+02  1.30000e-03 ...  2.31855e+01          nan\n",
      "           nan]]\n"
     ]
    }
   ],
   "source": [
    "x_test = df_test.iloc[ : , : -1].values\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a895afa3-63f3-4800-90f3-3b4de9e41ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [135]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/python/JupiterNotebook/virtualEnv/lib/python3.8/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Programming/python/JupiterNotebook/virtualEnv/lib/python3.8/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Programming/python/JupiterNotebook/virtualEnv/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/Programming/python/JupiterNotebook/virtualEnv/lib/python3.8/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/Programming/python/JupiterNotebook/virtualEnv/lib/python3.8/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6d65bb9b-876e-4259-a9ef-6ea918f9b5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0f66c-5c30-48bf-bdb3-f433eb6ba7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
